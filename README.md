# DataQ

DataQ is an MQTT Client for Axis cameras that enables custom data-driven solutions when standard camera data and formats are insufficient. It processes, filters, and transforms data before MQTT publishing to optimize resource usage.
Just like Axis Metadata, detections are based on DataQ makes integration and solution development very easy.  DataQ provides different data stractures based on use-case, optimizing bandwidth and alos adding pre-calculated properties like age, distance, direction and idle time so consumers does not need to.

***
## Key Features

**Data Processing**
- Pre-calculated properties that simplifies data processing.
- Resource-efficient publishing
- Optimized data transformation
- Real-time analytics processing
- WYSIWYG.  All overlays in video is generated by data published on MQTT.

**Data Filters**
- Data type publish
- Class labels
- Confidence level
- Area-of-intrest
- Min/Max width and height
- Max idle time (when objects are considered to be part of background)

- Real-time analytics processing
- Pre-calculated properties that simplifies data processing.

**Target Users**
- System integrators
- Custom solution developers
- Data-driven application builders

## Prerequisites
- Axis device (ARM7HF or AARCH64)
- The later the firmware provides better data
- MQTT Broker with WebSocket support
- MQTT client for data consumption

***

### Pre-compiled download
If you are only after a pre-compiled version, [Download Latest ZIP](https://www.dropbox.com/scl/fi/3z5ruobn27nvt2rwebqym/DataQ.zip?rlkey=etnpo7yvp2u6vqxi9d50hqpik&st=ian3s4md&dl=1)<br>
The ZIP file contains pre-compiled version for amrv7hf, aarach64 and this readme.<br>
It is a good idea to regularly download the latest version as new features and bug fixes are published.<br>

***

If you find this ACAP valuable, please consider [buying me a coffee](https://buymeacoffee.com/fredjuhlinl).  

***

## Data Types

### Events
Event-based triggers for actions, offering streamlined MQTT message publishing compared to standard Axis device capabilities.

### Object Analytics

**Detection Data**
- Real-time object detection
- Bounding box information
- Classification data
- High data throughput

**Tracker Data**
- Movement-based updates (and 2-second intervals)
- Direction, speed, and distance metrics
- Optimized bandwidth usage

**Path Data**
- Ideal for post-processing applications
  - Flow heatmaps
  - Dwell analysis
  - Forensic searching
  - Object counting
- Minimal bandwidth consumption and post processing needs

**Occupancy Data**
- Provides updates when number of detected objects in the scene changes
	- Queue management
	- Loitering

**Geospace Data**  
  
Geospace transforms the object detections x/y space in video to longitude and latitude. The technology used is homography.  
In order to get a good result, it is recommended that the calibration markers cover the area where objects move while maximizing the 4-corner area. It is also recommended to enable the camera's Barrel distortion correction (Menu | Installation | Image correction).  
You may add more than 4 markers if needed, but it may also make things worse.  

Geospace data uses Trackers for the transformations. Trackers do not need to be published but you may need to adjust both "Detections" and "Trackers".  
Recommended settings:  
* Enable the cameras Barrel distortion correction.
* Set Detections "Max idle" to 5 or 10 seconds to prevent sending location for stationary objects.
* Set Detection COG (Center-of-Gravity) to bottom-center.
* Disable all labels under Detections you are not interested in.
* Set Tracker "Minimum distance" to 5% or more to prevent stationary objects from being falsely detected as moving.

1. Click "Edit Markers".  
  - Use the mouse to move the map to the area the camera is located. Click "Save map"
  - Add 4 markers by clicking the left mouse in the video. A corresponding marker will be displayed in the map. 
	Move the markers to distinct positions (e.g. corner of a building)
	Marker is removed by right-clicking on the marker in the video view.  
  - Click "Save and calibrate"
2. Click "Verify"
  - Use the mouse and left-click in the video view. A marker will be shown in the map. See how well they correlate. You may need to go back to step 1 and adjust calibration.  
3. Click "Monitor"
  - Detected moving Objects will be displayed in both video and map view.

Check out the Node-RED example worldmap-flow.json under examples. Import the worldmap node and the worldmap-flow.json to your Node-RED. Configure the MQTT client.  

### Monitoring Data

**Status Data**
MQTT Heartbeat published every 15 minutes
- Network load monitoring
- CPU usage tracking
- Uptime statistics

## Integration Specifications

### Coordinate System
- Relative coordinates [0...1000][0...1000] (Aspect ratio independent)
- Origin: Top-left corner

### Data Properties

| Property   | Type / Format | Description & Usage |
|------------|---------------|---------------------|
| **id**     | `string` | Unique tracking ID assigned per object during its lifetime in the scene. Used as a primary key when correlating updates. |
| **type**   | `string` or `int` | Internal object type code (implementation detail). Typically maps to a `class` but may be model‑specific. Usually not needed unless doing low‑level integrations. |
| **class**  | `string` | Semantic classification label (e.g., `"Person"`, `"Car"`, `"Bike"`, `"Bag"`). Primary field to identify object categories for business logic (counts, alerts, analytics). |
| **active** | `boolean` | Indicates whether the object is currently visible/trackable. Useful for knowing when objects have exited the scene. |
| **x, y, w, h** | `int` (pixels) | Bounding box rectangle: top‑left `(x,y)` position and box size `(w,h)`. Used to draw boxes in UIs or compute relative object size. |
| **cx, cy** | `int` (pixels, normalized 0–1000 optional) | Object’s positional anchor point (center or bottom‑center). Used for tracking paths, heat maps, and trajectory analyses. |
| **dx, dy** | `int` (pixels or normalized units) | Net displacement `(current − initial)` in X and Y directions. Indicates travel direction: `dx > 0 = right`, `dy > 0 = down`. Useful for direction/flow detection. |
| **birth**  | `int` (epoch seconds/milliseconds) | Timestamp when the object first appeared. Used for age/duration calculations. |
| **bx, by** | `int` (pixels) | Position coordinates where the object first entered the scene. Can be used for entry‑point analysis. |
| **age**    | `float` (seconds) | Time since first detection. Key metric for dwell time, stay duration, and filtering short vs long presence. |
| **idle**   | `float` (seconds) | How long the object has been stationary (resets on movement). Supports use cases like idle vehicle/person detection, abandoned luggage, or loitering alerts. |
| **maxIdle**| `float` (seconds) | The maximum idle time the object had while in scene |
| **speed**  | `float`| The speed is distance/age and represents %movement of the view / seconds |
| **maxSpeed**  | `float`| The highest speed detected of the object |
| **confidence** | `int` (0–100) | Detection confidence score. Use thresholding to discard low-confidence objects and minimize false positives. |
| **timestamp**  | `int` (epoch seconds/milliseconds) | Last frame time where the object was seen. Useful for synchronization and gap detection. |
| **color, color2** | `string` (label) | Primary and secondary detected color labels (e.g., `"red"`, `"blue"`). Helps with descriptive analytics (red car, blue shirt). May be `null` if unavailable. |
| **anomaly**   | `string` (Reason) | Only included if the anomaly service detected anomaly in Tracker or paths |
| **path**   | `array` of objects | Sequence of position and dwell samples. Each entry contains `{x, y, d, lat?, lon?}`. Use to reconstruct trajectories, heatmaps, or identify where objects dwell most. |
| **lat, lon** | `float` (GPS coords) | Latitude/Longitude if a homography matrix is available. Enables geo‑position mapping in real-world coordinates instead of pixels. |
| **name**   | `string` | Camera name or location identifier (e.g., `"LobbyCam1"`). Useful for human-readable references. |
| **serial / device** | `string` | Unique hardware device identifier. Supports multi-camera/log correlation. |
| **localTime** | `string` (timestamp, local timezone) | Human‑readable local time when the event occurred. Useful for logs, reports, and non‑technical stakeholders. |

***

## Advanced Settings

The Advanced page provides tools for optimizing DataQ behavior in challenging scenes where the default analytics may produce fragmented or inaccurate data. Access it from the sidebar under **Advanced**.

### Perspective Guard

Defines a cut-off boundary on the camera view. When a tracked object's center crosses from inside to outside this boundary, the object is finalized and any subsequent reuse of the same tracker ID by the analytics engine is treated as a new, separate object.

**When to use:**  
In scenes with strong perspective (e.g., a street receding from the camera) where an outgoing object disappears at a distance and an incoming object is assigned the same tracker ID — creating a false path that reverses direction.

**Tips:**
- Draw the boundary generously so legitimate objects near the edge are not cut off prematurely.
- Objects that first appear *outside* the boundary are still tracked normally — the guard only fires on inside-to-outside transitions.
- Works independently of the Area-of-Interest filter on the Detections page.

### Object Stitching

Automatically merges path segments from the same physical object that temporarily disappears and reappears (e.g., a person walking behind a pillar). Without stitching, each disappearance produces a separate path; with stitching, they are joined into one continuous path.

**Settings:**
- **Max Duration (s)** — Maximum gap between the end of one path and the start of the next for them to be considered the same object (1–10 seconds).
- **Angle Threshold (°)** — Maximum allowed difference between the direction of the outgoing and incoming paths (0–90°). Set to 0 to ignore direction entirely.
- **Allow Class Switch** — When enabled, objects can be matched even if their classification label changes (e.g., "vehicle" → "car"). The label with the highest confidence is kept.
- **Stitch Area** — An area in the video where objects are expected to disappear and reappear. Only paths that end or start within this area are candidates for stitching.

**Tips:**
- Too large a duration or angle threshold may incorrectly merge different objects.
- Stitched paths are shown in green on the video overlay; normal paths in yellow.

### Tracker Predictions

When enabled, the analytics engine includes predicted positions for objects that are temporarily not visible. This helps maintain tracking continuity during brief occlusions.

**When to use:**  
In scenes where objects frequently pass behind obstacles (poles, pillars, signs) and you want smoother, more continuous tracking.

**Things to consider:**
- Predictions are estimates and may be inaccurate for objects that change speed or direction while occluded.
- **Changing this setting requires an ACAP restart** to take effect.
- May slightly increase CPU usage on the camera.

***

## Anomaly Detection Settings & Usage

The anomaly detection service helps highlight abnormal object behaviors in your scene, assisting users to focus attention where needed most. Objects marked with `"anomaly": "<reason>"` are flagged in MQTT data, and a stateful event is triggered as long as the anomaly persists.

### What is an Anomaly?

An anomaly indicates that an object’s movement or behavior deviates from what is defined as normal in your configuration. This is not about detecting intrusions, but about identifying outliers or unusual system activity that may merit review. Use anomaly detection to monitor for unexpected appearances, exits, motion patterns, loitering, or excessive speed—all customizable per your application needs.

### Configuration Overview

- **Object Type Selection:**  
  Choose to monitor anomalies for Humans, Vehicles, or both. Each type has separate statistics and behavior profiles for optimized detection.

- **Entry/Exit Areas:**  
  Specify one or more areas in the scene as normal entry/exit points. When an object appears or disappears outside these regions, it is flagged as an anomaly. Avoid using this feature if entries or exits can occur anywhere; restrict its use to controlled or predictable zones for reliable results.

- **Max Direction Changes:**  
  Set the maximum number of distinct direction changes an object can make before it is considered abnormal. This is useful for flagging zig-zag motion or non-standard traversal paths.

- **Horizontal/Vertical Direction:**  
  Define whether normal movement should be left/right (horizontal) or up/down (vertical). Default is “Any,” which means all directions are acceptable and won’t trigger anomalies on direction alone.

- **Max Idle Time:**  
  Establish how long an object may pause while traversing the view before being considered anomalously idle (e.g., loitering, stopping unexpectedly).

- **Max Age:**  
  Set how long an object is allowed to remain in the scene before being considered abnormal (e.g., extended dwell time).

- **Max Speed:**  
  Define what range of speeds are considered normal. Exceeding this speed will be flagged as an anomaly.

- **Disable Checks:**
  Setting any parameter to zero disables checking for that metric.

### System integration

On MQTT, Trackers and Paths will have an additional property "anomaly" with a "Reason".  
For VMS (Video Mananagement Systems"), a stateful event "anomaly" will be fired and stay high as long as there is detected anomaly.

### Practical Guidance

- **Statistics Area:**  
  The settings screen displays live statistics for the last 100 Humans and Vehicles detected, including lowest, average, highest, and 95% percentile values per metric. Let the system run for hours or days to collect baseline data and configure thresholds that fit your real-world conditions.

- **Iterative Tuning:**  
  Start with broad settings, observe flagged anomalies, and refine thresholds based on what you see in the statistics area. This prevents over-alerting and false positives, improving utility over time.

- **Entry/Exit Configuration:**  
  Only configure entry/exit areas if regular entry/exit points exist—otherwise unpredictable entrances/exits may yield excessive anomalies.

- **Event Triggering:**  
  Each anomaly triggers a stateful event while ongoing, allowing MQTT consumers to react in real-time (alert operators, record video, etc.).

### Best Practices

- Define "normal" based on your business goals and operational context (e.g., security, process monitoring, safety).
- Maintain clear records of configuration changes and review flagged events periodically to improve detection quality.
- Periodically review the anomaly statistics to ensure thresholds are set appropriately and adapt them as usage patterns evolve.
- Use the system’s data-driven insights—don’t rely solely on pre-set defaults.

***

## MQTT Configuration

### Broker Setup Options
- [Mosquitto](https://mosquitto.org/)  
  Add the following to your mosquitto.conf
  ```
  listener 1884
  protocol websockets
  ```
- [Node-RED AEDES](https://flows.nodered.org/node/node-red-contrib-aedes)  
  Bind WS port 1884 in the AEDES settings

### Requirements
- WebSocket support for data visualization in the user interface


> **Note**: This ACAP deprecates and replaces SIMQTT, ObjectTracker, ObjectPath and Occupancy  
> **Note**: Use DataQ when standard Axis device services and data formats do not meet your requirements.

***

## History

### 3.1.0 Mar 1, 2026
- New MQTT topic `image/{serial}`: publishes a JPEG snapshot (640×360 for 16:9 cameras) encoded as Base64
  - Published immediately when enabled and then daily at 12:00 local time
- `connect/{serial}` announcement now includes a `labels` array listing all detectable object classes with `id`, `name`, and `enabled` fields
- Added **Image** toggle to the MQTT streams table in the UI
- Renamed `path-structure.md` to `MQTT_topics.md` with full topic and payload documentation
- Added `publish.image` setting (default: disabled)

### 3.0.1 Feb 25, 2026
- Fixed OpenStreetMap not displaying on the Geospace page
- Fixed critical bug where homography matrix was not loaded at startup, causing all geospace transforms to fail until re-calibration
- Switched matrix library from single (float) to double precision for accurate GPS coordinate transformations
- Improved Geospace UI
  - Context-sensitive help text for each mode (Monitor, Calibrate, Validate)
  - Live marker count with calibration readiness feedback
  - Numbered tooltips on map markers matching video marker labels
  - Clear All button for resetting markers
  - Crosshair cursor and click indicator in Calibrate and Validate modes
  - Map auto-pans to validation result
  - Pre-save validation requiring minimum 4 markers
- Added re-projection error validation when calibrating homography
- Added input range validation for geospace HTTP endpoint
- Added confidence and distance fields to geospace MQTT messages
- Removed dead code and minor fixes

### 3.0.0 Feb 21, 2026
- New Advanced settings page for scene optimization
  - **Perspective Guard** — Cut-off boundary to prevent false path reversals in perspective scenes
  - **Object Stitching** — Automatic path merging for objects that temporarily disappear behind obstacles
  - **Tracker Predictions** — Enable predicted positions during brief occlusions for smoother tracking
- Enhanced path stitching functionality
  - Conditional angle threshold checking (setting to 0 disables direction matching)
  - Improved path holding logic for more reliable stitching behavior
  - Allow class switching — stitched paths can adopt the class from higher confidence segments
- UI improvements
  - Extended angle threshold range from 20-60° to 0-90° for greater flexibility
  - Updated help text to clarify that 0 = ignore direction
- Stability fixes
- Bug fixes

### 2.1.9 Jan 1, 2026
- Fixed critical deadlock vulnerability
- Fixed path dwell calculation
- Improved thread safety
- Added properties in connect and status publish

### 2.1.8 Nov 17
- Fixed time issues in Path.  Age and duration in path array is now correct.

### 2.1.7 Oct 3
- Settings are now correctly stored in Detections.

### 2.1.6 Sep 29
- Fixed client certificate authentication for MQTT
- Anomaly still in Beta
- Occupancy now working as expected
- Fixed a flaw that prevented users from updating the Detections areas

### 2.1.1 Sep 24

- Marked Anomaly as "Beta" as testing is ongoing.  
  Please send comments, questions, error reports and suggestions for improvements.  

### 2.1.0 Sep 23
- Added anomaly detection. Trackers and Path are marked with property "anomaly": "The reason".  
  Vehicles and humans are treated individually
	* Normal Entry areas (first detected position)
    * Normal Exit Areas (last detected position)
    * Max numbers of direction changes (zig-zag movement)
    * Max idle time
    * Max age
    * Vertical movement (Wrong way)
    * Horizontal movement (Wrong way)
    * Max Speed
- Trackers are now published immediately when detected. Previous behavior required new object to move.
- Box area selection has been updated.

### 2.0.4 Sep 12
- Fixed Occupancy to have the value of the number of each detected labels.

### 2.0.3 Sep 7
- Path timestamp is now correct

### 2.0.2 Sep 2
- Fixed WEB GUI screw up, displaying the wrong index page.
  
### 2.0.0 July 14

- Major code refactoring for enhanced stability and future compatibility, especially across varying camera firmware versions.
  - Upgraded to SDK 12.2 (from SDK 3.5) for improved long-term support.
  - Switched MQTT library from synchronous to asynchronous, providing more robust reconnect and connection management.
  - Improved object detection pipeline to better accommodate firmware differences and prepare for upcoming changes.
- Introduced new `"idle"` property, which reports how long (in seconds) an object has remained stationary. This value resets when movement is detected.
- Occupancy analytics now allow you to count stationary objects, moving objects, or both, giving more flexibility and precision in reporting.

### 1.5.0	June 14, 2025
- Optimized Detections datastructure by reducing its size (peopertieas removed)
- Updated MQTT to use the MQTTAsync client.

### 1.4.6	May 14, 2025
- Fixed a bug that caused respawn of the ACAP

### 1.4.5	May 6, 2025
- Fixed MQTT reconnect issue

### 1.4.4	April 14, 2025
- Perodically force re-connection if needed as lostConnection may be missed
- Fixed LWT topic

### 1.4.3	April 14, 2025
- Reset the client on re-connect
- Fixed LWT topic

### 1.4.2	March 23, 2025
- Improved MQTT Reconnection stability

### 1.4.1	March 13, 2025
- Added Geospace data (Check documentation above).
- Added web page MQTT connection message box to know if the web page is connected or not.
- Bug fixes

### 1.3.0	March 3, 2025
- Replaced "Max age" with "Max idle".  
  When Max idle time is set, detections are not published when after not moving X seconds.  
  When the object starts moving, the same object ID will be used when publishing. Age, birth and distance will be preserved.    
  Occupancy is impacted and will not count idle objects.  
  Path will be published when object is idle.  
- Restructuring GUI

### 1.2.10	March 3, 2025
- Fixed MQTT TLS flaws introduced in refactoring (1.2.9)

### 1.2.9	March 2, 2025
- Refactoring MQTT client
  * Announcement retained message
  * Disconnect retained message
- User interface updates

### 1.2.8	February 22, 2025
- Created a new Menu "Scene" to be used to monitor and configure scene behavior
- Added support for enabling low confident trackers.
- Added temporarily enabling publishing for objects needed for a specific page if the publishing is disabled. The publishing will be disabled again when leaving the page.
- Fixed MQTT stability (recurring disconnects)
- Added WSS port and a way to enforce the client to use WSS even for pages accessed with HTTP. WSS will always be used when a page is accessed over HTTP.

### 1.2.7	February 12, 2025
- Fixed logic and reference flaws.
  Pull Request from InSupport

### 1.2.6	February 9, 2025
- Fixed support for data visualization when accessing camera over HTTPS with Secure WebSockets in client

### 1.2.5	February 3, 2025
- Adjustments on MQTT payload for path
- Allow multiple web browsers (and tabs) visualize MQTT messages

### 1.2.0	February 3, 2025
- Fixed "hanging-objects" due to changes in Axis OS12
- Fixed a memory leak (event processing)
- Fixed faulty center-of-gravity when camera is rotated
- Detections filter will only impact Occupancy but no longer Trackers & Paths
- Tracker filter impacts Path

### 1.1.1	January 23, 2025
- Corrected Object Detection post-processing 

### 1.1.0	January 18, 2025
- Objects are now only tracked within Area-Of-Interest
- Added Scene Max Age (Detections) that defines how old an object needs to be before being ignored. Typically used for Occupancy.
- Added Occupancy

### 1.0.2	January 14, 2025
- Initial commit
